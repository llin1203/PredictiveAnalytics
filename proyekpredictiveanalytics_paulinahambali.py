# -*- coding: utf-8 -*-
"""ProyekPredictiveAnalytics_PaulinaHambali.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/113qaaEN65EW3L9sMFoTaxGccgWv0xmAV

# Proyek Predictive Analytics: Diabetes Risk Prediction
## Dataset-Source: https://www.kaggle.com/datasets/whenamancodes/predict-diabities

### **by Paulina Hambali - MC009D5X2419**

## Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
# Data handling & analysis
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Machine learning models dan evaluasi
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import  OneHotEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Supaya grafik tampil di notebook
# %matplotlib inline

#kagglehub
import kagglehub

"""## Data Loading

"""

# Download Dataset
path = kagglehub.dataset_download("whenamancodes/predict-diabities")
print("Path to dataset files:", path)

# Read Dataset
file_path = path + "/diabetes.csv"
df = pd.read_csv(file_path)

"""## Exploratory Data Analysis (EDA)"""

# Rows in dataset
df.head()

# Total rows and column in dataset & desc column
print("Jumlah rows dan column: ",(df.shape))
print(df.columns)

# Type data check
df.info()

# Check missing values
df.isnull().sum()

# Descriptive Statistic
df.describe()

# Check target class
print(df['Outcome'].value_counts())
print(df['Outcome'].unique())

# Visualization: distribution of target class
sns.countplot(x='Outcome', data=df)
plt.title('Distribution of Target Class: Outcome')
plt.xlabel('Class')
plt.ylabel('Total')
plt.show()

# Visualization: distribution of numeric feature
numerical_col= df.select_dtypes(include=['int64', 'float64']).columns.tolist()

for feature in numerical_col:
    plt.figure(figsize=(12,5))
    plt.subplot(1, 2, 1)
    sns.histplot(df[feature], bins=30, kde=True)
    plt.title(f'Histogram: {feature}')

# Visualization: correlation between feature and target & Outlier (only numeric feature)
target = 'Outcome'
numerical_col = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
if target in numerical_col:
    numerical_col.remove(target)

for feature in numerical_col:
    plt.figure(figsize=(8, 5))
    sns.boxplot(x=target, y=feature, data=df)
    plt.title(f'{feature} vs {target}', fontsize=14)
    plt.xlabel(target, fontsize=12)
    plt.ylabel(feature, fontsize=12)
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10)
    plt.tight_layout()
    plt.show()

"""## Data Preparation"""

# Feature and Target
X = df.drop('Outcome', axis=1)
y = df['Outcome']

# Data split (Train-Test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Feature Scaling (Normalization)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""## Modelling"""

# Dataframe
models = pd.DataFrame(index=['train_acc', 'test_acc'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

# KNN
knn = KNeighborsClassifier(n_neighbors=10)
knn.fit(X_train, y_train)
models.loc['train_acc', 'KNN'] = accuracy_score(y_train, knn.predict(X_train))
models.loc['test_acc', 'KNN'] = accuracy_score(y_test, knn.predict(X_test))

# Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
models.loc['train_acc', 'RandomForest'] = accuracy_score(y_train, rf.predict(X_train))
models.loc['test_acc', 'RandomForest'] = accuracy_score(y_test, rf.predict(X_test))

# Boosting
gb = GradientBoostingClassifier(random_state=42)
gb.fit(X_train, y_train)
models.loc['train_acc', 'Boosting'] = accuracy_score(y_train, gb.predict(X_train))
models.loc['test_acc', 'Boosting'] = accuracy_score(y_test, gb.predict(X_test))

"""## Evaluation"""

# Hasil Models
models

# Bar Chart Models
fig, ax = plt.subplots()
models.sort_index(level='test_acc', ascending=False).T.plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

# Classification Report
model_dict = {
    'KNN': knn,
    'RandomForest': rf,
    'Boosting': gb
}

print("Classification Report")
for name, model in model_dict.items():
    print(f"\nModel: {name}")
    y_pred = model.predict(X_test)
    report = classification_report(y_test, y_pred)
    print(report)

# Final Evaluation Report
report_dict = {}
for name, model in model_dict.items():
    y_pred = model.predict(X_test)
    report = classification_report(y_test, y_pred, output_dict=True)
    report_dict[name] = {
        'Precision (0)': report['0']['precision'],
        'Recall (0)': report['0']['recall'],
        'F1-score (0)': report['0']['f1-score'],
        'Precision (1)': report['1']['precision'],
        'Recall (1)': report['1']['recall'],
        'F1-score (1)': report['1']['f1-score'],
        'Accuracy': report['accuracy']
    }
report_df = pd.DataFrame(report_dict).T
print(report_df.round(3))