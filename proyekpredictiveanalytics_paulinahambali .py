# -*- coding: utf-8 -*-
"""ProyekPredictiveAnalytics_PaulinaHambali.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/113qaaEN65EW3L9sMFoTaxGccgWv0xmAV

# Proyek Predictive Analytics: Diabetes Risk Prediction
## Proyek ini bertujuan untuk menerapkan prediksi analitik dalam memprediksi  kemungkinan seseorang mengidap penyakit diabetes atau tidak, berdasarkan data medis terkait (seperti kadar glukosa, tekanan darah, BMI, usia, dll). Beberapa algoritma klasifikasi digunakan untuk membangun model prediksi, seperti: K-Nearest Neighbors (KNN), Random Forest, dan Gradient Boosting
## **Dataset-Source:** https://www.kaggle.com/datasets/whenamancodes/predict-diabities

### **by Paulina Hambali - MC009D5X2419**

## Import Library
Import library digunakan untuk mengimport ke dalam notebook Proyek Diabetes Risk Prediction.
"""

# Data handling-analysis
import pandas as pd

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Machine learning models dan evaluasi
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report

#kagglehub
import kagglehub

"""Beberapa library yang diimport, mencakup:


*   **pandas** digunakan untuk manipulasi data seperti membaca dan menampilkan data dari dataset yang digunakan
*   **matplotlib.pyplot** digunakan untuk menvisualisasi dataset, salah satunya seperti labeling.
* **seaborn as sns** digunakan untuk menvisualisasi dataset, salah satunya dalam membangun grafik, seperti hisplot (histogram).
* **sckit-learn (sklearn)** digunakan untuk pemodelan dan evaluasi dalam machine learning.
* **sklearn.model_selection** digunakan untuk import train-test split data.
* **sklearn.preprocessing StandarScaler** digunakan untuk normalisasi (standarisasi) fitur numerik dalam dataset.
* **sklearn.neighbors KNeighborsClassifier** digunakan untuk import model KNN.
* **sklearn.ensemble RandomForest, GradientBoostingClassifier** digunakan untuk import model Random Forest dan GradienBoosting.
* **sklearn.metrics accuracy score** digunakan untuk import akurasi skor untuk evaluasi model yang digunakan.
* **sklearn.metrics classification_report** digunakan untuk import laporan klasifikasi mencakup f1-score, recall, precission, dan akurasi untuk evaluasi model yang digunakan.
* **kagglehub** digunakan untuk mengakses dataset dari kaggle secara langsung.

## Data Loading
"""

# Download Dataset
path = kagglehub.dataset_download("whenamancodes/predict-diabities")
print("Path to dataset files:", path)

"""**Download Dataset:** mengunduh dataset langsung dari kaggle, dataset yang digunakan untuk prediksi potensi dataset berasal dari whenamancodes dengan nama dataset predict-diabities. Akan dilakukan perintah **print** untuk menampilkan dataset berhasil dicetak pada path (lokasi) file."""

# Read Dataset
file_path = path + "/diabetes.csv"
df = pd.read_csv(file_path)

"""**Read Dataset:** **membaca** file csv bernama **diabetes.csv** dan dataset **disimpan** dalam dataframe bernama **df**.

## Exploratory Data Analysis (EDA)
"""

# Rows in dataset
df.head()

"""**Rows in dataset:** **membaca lima baris pertama** dalam dataset, mencakup **semua kolom** dan hanya menampilkan lima baris, indeks dimulai dari 0-4. Dimana terdapat beberapa fitur yang digunakan untuk prediksi potensi diabetes, yaitu
* Pregnancies: Jumlah kehamilan
* Glucose: Kadar glukosa dalam darah
* BloodPressure: Tekanan darah diastolik
* SkinThickness: Ketebalan lipatan kulit triceps
* Insulin: Kadar insulin serum
* BMI: Indeks massa tubuh
* DiabetesPedigreeFunction: Riwayat genetik diabetes
* Age: Umur
* Outcome: Label target (1 = Diabetes, 0 = Tidak Diabetes) — target
"""

# Total rows and column in dataset & desc column
print("Jumlah rows dan column: ",(df.shape))
print(df.columns)

"""**Total rows and column in dataset & desc column:** mencetak **jumlah baris dan kolom dengann menggunakan df.shape()**, dimana **baris ada 768 baris dan kolom terdapat 9** dan **mencetak semua kolom dengan df.columns.**"""

# Type data check
df.info()

"""**Type data check:** Digunakan untuk **cek tipe data** yang ada pada df (dataset yang digunakan) dimana, semua data dalam kolom df bernilai **numerik** hanya ada **integer** (bilangan bulat) dan **float** (bilangan desimal)."""

# Check missing values
df.isnull().sum()

"""**Check Missing Values:** Digunakan untuk **cek apakah dalam df terdapat nilai null atau tidak** menggunakan **df.isnull().sum()** dan hasilnya **tidak ada nilai null didalamnya.**"""

# Descriptive Statistic
df.describe()

""" **Descriptive Statistic:** digunakan untuk **mendeskripsikan statistik** dalam df menggunakan **df.describe()** didalamnya terdapat data terkait mean (rata-rata), std (standar deviasi), min (nilai minimal), max (nilai maksimal), 25% kuartil pertama(q1), count (jumlah data), 50% median (q2), dan 75% kuartil ketiga (q3)."""

# Check target class
print(df['Outcome'].value_counts())
print(df['Outcome'].unique())

"""**Check target outcome:** digunakan untuk memastikan kelas target, dimana df['Outcome'].value_counts() digunakan untuk menghitung jumlah masing-masing nilai dalam kolom Outcome. df['Outcome'].unique() digunakan untuk melihat jenis nilai unik yang terdapat dalam kolom tersebut. Dimana nilai dalam outcome diinterpretasikan dengan:


*   0 → menunjukkan bukan penderita diabetes
*   1 → menunjukkan penderita diabetes
"""

# Visualization: distribution of target class
sns.countplot(x='Outcome', data=df)
plt.title('Distribution of Target Class: Outcome')
plt.xlabel('Class')
plt.ylabel('Total')
plt.xticks([0, 1], ['Non-Diabetic', 'Diabetic'])
plt.show()

"""**Visualization: distribution of target class:** digunakan untuk visualisasi distribusi kelas dalam bentuk bar chart (grafik batang) dalam outcome yakni ada 0 (bukan penderita diabetes/ non-diabetic) dan 1 (pengidap diabetes/diabetic)."""

# Visualization: distribution of numeric feature
numerical_col= df.select_dtypes(include=['int64', 'float64']).columns.tolist()

for feature in numerical_col:
    plt.figure(figsize=(12,5))
    plt.subplot(1, 2, 1)
    sns.histplot(df[feature], bins=30, kde=True)
    plt.title(f'Histogram: {feature}')

"""**Visualization: distribution of numeric feature:** digunakan untuk visualisasi histogram fitur numerik, mencakup semua kolom dalam df karena semua bernilai numerik."""

# Visualization: correlation between feature and target & Outlier (only numeric feature)
target = 'Outcome'
numerical_col = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
if target in numerical_col:
    numerical_col.remove(target)

for feature in numerical_col:
    plt.figure(figsize=(8, 5))
    sns.boxplot(x=target, y=feature, data=df)
    plt.title(f'{feature} vs {target}', fontsize=14)
    plt.xlabel(target, fontsize=12)
    plt.ylabel(feature, fontsize=12)
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10)
    plt.tight_layout()
    plt.show()

"""**Visualization: correlation between feature and target & Outlier (only numeric feature):** digunakan untuk menvisualisasi korelasi (hubungan) antar fitur target yaitu outcome dan fitur numerik mencakup pregnancies, glucose, bloodpressure, skinthickness, insulin, BMI, diabetespedigreefunction, dan age.

## Data Preparation
"""

# Feature and Target
X = df.drop('Outcome', axis=1)
y = df['Outcome']

""" **Feature and Target:** digunakan untuk memisahkan feature dan target, dimana fitur (X) berupa variabel independen (input) dan target(y) berupa variabel dependen yang berarti akan diprediksi."""

# Data split (Train-Test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

"""**Data split (Train-Test):** Membangi data menjadi 80% untuk train dan 20% untuk test."""

# Feature Scaling (Normalization)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""**Feature Scaling (Normalization):** digunakan untuk normalisasi fitur agar fitur memiliki skala yang sama.

## Modelling
"""

# Dataframe
models = pd.DataFrame(index=['train_acc', 'test_acc'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""**Dataframe:** Digunakan untuk membuat dataframe kosong untuk menyimpan akurasi dari setiap model yang digunakan, yakni KNN, RandomForest dan boosting."""

# KNN
knn = KNeighborsClassifier(n_neighbors=10)
knn.fit(X_train, y_train)
models.loc['train_acc', 'KNN'] = accuracy_score(y_train, knn.predict(X_train))
models.loc['test_acc', 'KNN'] = accuracy_score(y_test, knn.predict(X_test))

"""**KNN:** K-Nearest Neighbors (KNN) model yang digunakan, dimana dilakukan perhitungan akurasi model pada data pelatihan (X_train, y_train) dan data pengujian (X_test, y_test).
* knn = KNeighborsClassifier(n_neighbors=10) memprediksi kelas dari 10 tetangga terdekat.
* knn.fit(X_train, y_train) model dilatih
* models.loc['train_acc', 'KNN'] = accuracy_score(y_train, knn.predict(X_train)) melakukan prediksi pada train data dan mencatat akurasinya.
* models.loc['test_acc', 'KNN'] = accuracy_score(y_test, knn.predict(X_test)) melakukan prediksi pada melakukan prediksi pada test data dan mencatat akurasinya.
"""

# Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
models.loc['train_acc', 'RandomForest'] = accuracy_score(y_train, rf.predict(X_train))
models.loc['test_acc', 'RandomForest'] = accuracy_score(y_test, rf.predict(X_test))

"""**Random Forest:** model yang digunakan, dimana dilakukan perhitungan akurasi model pada data pelatihan (X_train, y_train) dan data pengujian (X_test, y_test).

*  rf = RandomForestClassifier(random_state=42) membuat model Random Forest dengan seed acak 42 untuk hasil yang konsisten.
* rf.fit(X_train, y_train) model dilatih menggunakan data pelatihan.
* models.loc['train_acc', 'RandomForest'] = accuracy_score(y_train, rf.predict(X_train)) melakukan prediksi pada train data dan mencatat akurasinya.
* models.loc['test_acc', 'RandomForest'] = accuracy_score(y_test, rf.predict(X_test)) melakukan prediksi pada test data dan mencatat akurasinya.
"""

# Boosting
gb = GradientBoostingClassifier(random_state=42)
gb.fit(X_train, y_train)
models.loc['train_acc', 'Boosting'] = accuracy_score(y_train, gb.predict(X_train))
models.loc['test_acc', 'Boosting'] = accuracy_score(y_test, gb.predict(X_test))

"""**Boosting:** Gradient Boosting model yang digunakan, dimana dilakukan perhitungan akurasi model pada data pelatihan (X_train, y_train) dan data pengujian (X_test, y_test).

* gb = GradientBoostingClassifier(random_state=42) membuat model Gradient Boosting dengan nilai acak tetap (random_state) agar hasil replikasi konsisten.
* gb.fit(X_train, y_train) model dilatih menggunakan data pelatihan.
* models.loc['train_acc', 'Boosting'] = accuracy_score(y_train, gb.predict(X_train)) melakukan prediksi pada train data dan mencatat akurasinya.
* models.loc['test_acc', 'Boosting'] = accuracy_score(y_test, gb.predict(X_test)) melakukan prediksi pada trest data dan mencatat akurasinya.

## Evaluation
"""

# Hasil Models
models

"""**Hasil Models:** digunakan untuk menampilkan hasil modelling yang telah dilakukan mencakup tiga models dari train dan test."""

# Bar Chart Models
fig, ax = plt.subplots()
models.sort_index(level='test_acc', ascending=False).T.plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""**Bar Chart Models:** Melakukan visualisasi dari hasil modelling terkait tiga model KNN, RandomForest dan Boosting dakam barchart."""

# Classification Report
model_dict = {
    'KNN': knn,
    'RandomForest': rf,
    'Boosting': gb
}

print("Classification Report")
for name, model in model_dict.items():
    print(f"\nModel: {name}")
    y_pred = model.predict(X_test)
    report = classification_report(y_test, y_pred)
    print(report)

""" **Classification Report:** dilakukan evaluasi performa dari masing-masing model klasifikasi (KNN, Random Forest, dan Boosting) dengan menampilkan classification report pada data pengujian (X_test, y_test).
 * Dictionary model_dict dibuat untuk menyimpan semua model yang sudah dilatih, supaya gampang di-loop satu per satu.
 * Hasil prediksi dibandingkan dengan y_test, dan ditampilkan classification report menggunakan classification_report().
 * Berikut penjelasan dari classification report:
* Precision	Dari semua yang diprediksi positif, berapa banyak yang benar?
* Recall	Dari semua yang benar-benar positif, berapa banyak yang terdeteksi?
* F1-score	Rata-rata harmonik dari precision dan recall (kombinasi keduanya).
* Support	Jumlah data asli dari masing-masing kelas (0 dan 1).
* Accuracy	Berapa proporsi prediksi yang benar secara keseluruhan.


"""

# Final Evaluation Report
report_dict = {}
for name, model in model_dict.items():
    y_pred = model.predict(X_test)
    report = classification_report(y_test, y_pred, output_dict=True)
    report_dict[name] = {
        'Precision (0)': report['0']['precision'],
        'Recall (0)': report['0']['recall'],
        'F1-score (0)': report['0']['f1-score'],
        'Precision (1)': report['1']['precision'],
        'Recall (1)': report['1']['recall'],
        'F1-score (1)': report['1']['f1-score'],
        'Accuracy': report['accuracy']
    }
report_df = pd.DataFrame(report_dict).T
print(report_df.round(3))

"""**Final Classification Report:**  tabel evaluasi akhir dari ketiga model klasifikasi (KNN, Random Forest, Boosting) dengan metrik utama: Precision, Recall, dan F1-score untuk masing-masing kelas (0 dan 1) serta Accuracy keseluruhan model.
* 0 = Bukan pengidap diabetes
* 1 = Pengidap diabetes

Digunakan classification_report(..., output_dict=True) untuk ambil hasil evaluasi dalam format dictionary.Lalu akan mengambil metrik per kelas dan akurasi, simpan dalam report_dict. Terakhir, dikonversi ke DataFrame (report_df) dan tampilkan hasilnya.

Kesimpulan:
* Random Forest memiliki akurasi tertinggi (83%) dan performa seimbang di kedua kelas, menghasilkan model terbaik secara umum.

* Boosting cukup kuat, pada recall kelas 1 (penting jika ingin meminimalkan false negative).

* KNN memiliki akurasi paling rendah dan recall kelas 1 yang rendah, sehingga kurang optimal untuk kasus ini.
"""